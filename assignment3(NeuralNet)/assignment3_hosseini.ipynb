{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599b15ca",
   "metadata": {},
   "source": [
    "You are tasked with developing a Neural Network (NN) model to predict the gcPBM TF-DNA\n",
    "binding affinity for three TFs: Max, Mad, and Myc, using a given DNA sequence, similar to your\n",
    "approach in Assignment 1. In this task, we will exclusively utilize 1-mer features. Implement\n",
    "10-fold cross-validation to determine the average r-squared value. [2pt]\n",
    "\n",
    "Hint: Your NN should include a minimum of two hidden layers equipped with an adequate\n",
    "number of nodes. For the final layer, integrate a Dense(1) unit followed by a sigmoid activation\n",
    "function. Opt for mean squared error (mse) as your loss function, utilize the Adam optimizer, and\n",
    "apply the ‘R2Score’ metric to ascertain the r-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6ad2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.optimizers.legacy import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "688d4582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, header=None):\n",
    "    if header == None:\n",
    "        df = pd.read_table(path, delimiter='\\t', header = header, names = ['sequence', 'affinity'])\n",
    "    else:\n",
    "        df = pd.read_table(path, delimiter='\\t').rename(columns={\"SymmetrizedAffinity\": \"affinity\", \"Kmer\":\"sequence\"})\n",
    "        df = df.drop(columns=['idx'])\n",
    "    df['affinity'] = df['affinity'].astype(float)\n",
    "    return df\n",
    "    \n",
    "max_df = load_data('Max.txt')\n",
    "mad_df = load_data('Mad.txt')\n",
    "myc_df = load_data('Myc.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3ccd365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_1mer(seq):\n",
    "    temp = list(seq.replace('A', '1000').replace('C', '0100').replace('G', '0010').replace('T','0001'))\n",
    "    return [int(x) for x in temp]\n",
    "\n",
    "def one_hot_encode_2mer(seq):\n",
    "    str = ''\n",
    "    for i in range(len(seq)-1):\n",
    "        str += seq[i:i+2].replace('AA', '1000000000000000').replace('AC', '0100000000000000').replace('AG', '0010000000000000').replace('AT', '0001000000000000').replace('CA', '0000100000000000').replace('CC', '0000010000000000').replace('CG', '0000001000000000').replace('CT', '0000000100000000').replace('GA', '0000000010000000').replace('GC', '0000000001000000').replace('GG', '0000000000100000').replace('GT', '0000000000010000').replace('TA', '0000000000001000').replace('TC', '0000000000000100').replace('TG', '0000000000000010').replace('TT', '0000000000000001')\n",
    "    return [int(x) for x in list(str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc957ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, encoding='1mer', normalize=True):\n",
    "    if normalize == True:\n",
    "        min_val = min(df['affinity'])\n",
    "        max_val = max(df['affinity'])\n",
    "        df['affinity'] = df['affinity'].apply(lambda x: (x - min_val)/(max_val - min_val))\n",
    "    sequences = df['sequence'].to_list()\n",
    "    affinities = df['affinity'].to_list()\n",
    "    if encoding == '1mer':\n",
    "        X = np.array([one_hot_encode_1mer(x) for x in sequences])\n",
    "    else: \n",
    "        X = np.array([one_hot_encode_2mer(x) for x in sequences])\n",
    "    y = np.array(affinities)\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    return X, y, cv\n",
    "\n",
    "max_X, max_y, max_cv = preprocess_data(max_df, '1mer')\n",
    "mad_X, mad_y, mad_cv = preprocess_data(mad_df, '1mer')\n",
    "myc_X, myc_y, myc_cv = preprocess_data(myc_df, '1mer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35dd1884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 843us/step - loss: 0.0038 - r2_score: 0.8589\n",
      "27/27 [==============================] - 0s 788us/step - loss: 0.0042 - r2_score: 0.8566\n",
      "27/27 [==============================] - 0s 778us/step - loss: 0.0044 - r2_score: 0.8545\n",
      "27/27 [==============================] - 0s 803us/step - loss: 0.0042 - r2_score: 0.8545\n",
      "27/27 [==============================] - 0s 796us/step - loss: 0.0046 - r2_score: 0.8191\n",
      "27/27 [==============================] - 0s 769us/step - loss: 0.0039 - r2_score: 0.8703\n",
      "27/27 [==============================] - 0s 803us/step - loss: 0.0062 - r2_score: 0.7992\n",
      "27/27 [==============================] - 0s 787us/step - loss: 0.0075 - r2_score: 0.7329\n",
      "27/27 [==============================] - 0s 768us/step - loss: 0.0044 - r2_score: 0.8443\n",
      "27/27 [==============================] - 0s 781us/step - loss: 0.0046 - r2_score: 0.8530\n",
      "Average r-squared for Max: 0.8343277990818023\n",
      "24/24 [==============================] - 0s 752us/step - loss: 0.0048 - r2_score: 0.8835\n",
      "24/24 [==============================] - 0s 789us/step - loss: 0.0052 - r2_score: 0.8855\n",
      "24/24 [==============================] - 0s 787us/step - loss: 0.0046 - r2_score: 0.9049\n",
      "24/24 [==============================] - 0s 869us/step - loss: 0.0049 - r2_score: 0.8851\n",
      "24/24 [==============================] - 0s 792us/step - loss: 0.0042 - r2_score: 0.9040\n",
      "24/24 [==============================] - 0s 832us/step - loss: 0.0048 - r2_score: 0.8919\n",
      "24/24 [==============================] - 0s 836us/step - loss: 0.0045 - r2_score: 0.8981\n",
      "24/24 [==============================] - 0s 816us/step - loss: 0.0043 - r2_score: 0.9050\n",
      "24/24 [==============================] - 0s 796us/step - loss: 0.0051 - r2_score: 0.8929\n",
      "24/24 [==============================] - 0s 753us/step - loss: 0.0046 - r2_score: 0.8996\n",
      "Average r-squared for Mad: 0.8950340747833252\n",
      "22/22 [==============================] - 0s 754us/step - loss: 0.0058 - r2_score: 0.8458\n",
      "22/22 [==============================] - 0s 790us/step - loss: 0.0058 - r2_score: 0.8417\n",
      "22/22 [==============================] - 0s 837us/step - loss: 0.0049 - r2_score: 0.8622\n",
      "22/22 [==============================] - 0s 840us/step - loss: 0.0048 - r2_score: 0.8638\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.0056 - r2_score: 0.8370\n",
      "22/22 [==============================] - 0s 967us/step - loss: 0.0055 - r2_score: 0.8486\n",
      "22/22 [==============================] - 0s 796us/step - loss: 0.0048 - r2_score: 0.8588\n",
      "22/22 [==============================] - 0s 783us/step - loss: 0.0048 - r2_score: 0.8649\n",
      "22/22 [==============================] - 0s 961us/step - loss: 0.0049 - r2_score: 0.8679\n",
      "22/22 [==============================] - 0s 877us/step - loss: 0.0049 - r2_score: 0.8674\n",
      "Average r-squared for Myc: 0.8558035135269165\n"
     ]
    }
   ],
   "source": [
    "def train_nn_model(X, y, cv, input_dimension, learning_rate):\n",
    "    r_squared_values = []\n",
    "    for train_index, test_index in cv.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = None\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape =(input_dimension)))\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        model.compile(loss='MeanSquaredError',\n",
    "             optimizer=Adam(learning_rate=0.001),\n",
    "             metrics=['R2Score'])\n",
    "        model.fit(X_train, y_train, batch_size=100, epochs=20, verbose=None)\n",
    "        score = model.evaluate(X_test, y_test)\n",
    "#         print('Total loss on testing data:', score[0])\n",
    "#         print('Accuracy of testing data:', score[1])\n",
    "        r_squared_values.append(score[1])\n",
    "    return np.mean(r_squared_values)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    print(f\"Average r-squared for Max: {train_nn_model(max_X, max_y, max_cv, 144, 0.001)}\")\n",
    "    print(f\"Average r-squared for Mad: {train_nn_model(mad_X, mad_y, mad_cv, 144, 0.001)}\")\n",
    "    print(f\"Average r-squared for Myc: {train_nn_model(myc_X, myc_y, myc_cv, 144, 0.001)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb56945c",
   "metadata": {},
   "source": [
    "Compare the performance of the neural network using 1-mer features against the linear\n",
    "regression models that utilize both 1-mer and 2-mer encodings for Max, Mad, and Myc. Discuss\n",
    "your observations on their performance. Specifically, analyze why the neural network model\n",
    "with 1-mer data yields satisfactory outcomes, offering an explanation for this observation. [1pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c837f9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9df06ab1",
   "metadata": {},
   "source": [
    "Create a function capable of encoding 1-mer and 2-mer sequences, including sequences with\n",
    "5-methylcytosine, denoted as ‘M’. [2pt]\n",
    "\n",
    "Hint: For 1-mer encoding, use the following representations: A as 10000, C as 01000, G as 00100,\n",
    "T as 00010, and M as 00001. For 2-mer encoding, start with AA represented as\n",
    "1000000000000000000000000, proceed through combinations like AC as\n",
    "0100000000000000000000000, and conclude with MM as 0000000000000000000000001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7121b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_1mer(seq):\n",
    "    temp = list(seq.replace('A', '10000').replace('C', '01000').replace('G', '00100').replace('T','00010').replace('M', '00001'))\n",
    "    return [int(x) for x in temp]\n",
    "\n",
    "def one_hot_encode_2mer(seq):\n",
    "    encoding = ''\n",
    "    encoding_map_2mer = {\n",
    "    'AA': '1000000000000000000000000', 'AC': '0100000000000000000000000', 'AG': '0010000000000000000000000', \n",
    "    'AT': '0001000000000000000000000', 'AM': '0000100000000000000000000', 'CA': '0000010000000000000000000', \n",
    "    'CC': '0000001000000000000000000', 'CG': '0000000100000000000000000', 'CT': '0000000010000000000000000',\n",
    "    'CM': '0000000001000000000000000', 'GA': '0000000000100000000000000', 'GC': '0000000000010000000000000', \n",
    "    'GG': '0000000000001000000000000', 'GT': '0000000000000100000000000', 'GM': '0000000000000010000000000',\n",
    "    'TA': '0000000000000001000000000', 'TC': '0000000000000000100000000', 'TG': '0000000000000000010000000', \n",
    "    'TT': '0000000000000000001000000', 'TM': '0000000000000000000100000', 'MA': '0000000000000000000010000',\n",
    "    'MC': '0000000000000000000001000', 'MG': '0000000000000000000000100', 'MT': '0000000000000000000000010',\n",
    "    'MM': '0000000000000000000000001'\n",
    "    }\n",
    "    for i in range(len(seq) - 1):\n",
    "        dinucleotide = seq[i:i + 2]\n",
    "        encoding += encoding_map_2mer[dinucleotide]\n",
    "    return [int(x) for x in list(encoding)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3104cc0",
   "metadata": {},
   "source": [
    "Load and encode the EpiSelex-seq data for the TFs Atf4 (Atf4.txt) and Cebpb (Cebpb.txt). Apply\n",
    "the neural network model you developed in Question 1 and linear regression models using\n",
    "1-mer and 2-mer features to predict their binding affinity to both methylated and unmethylated\n",
    "DNA sequences. Note that the binding data is unaligned. [2pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ed661b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/hiradh/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/hiradh/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/hiradh/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/hiradh/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/hiradh/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/hiradh/miniconda3/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_95\" is incompatible with the layer: expected shape=(None, 225), found shape=(None, 50)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m atf_X, atf_y, atf_cv \u001b[38;5;241m=\u001b[39m preprocess_data(atf_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1mer\u001b[39m\u001b[38;5;124m'\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/CPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Neural Net r-squared for Atf4 1-mer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtrain_nn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43matf_X\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43matf_y\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43matf_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m225\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 18\u001b[0m, in \u001b[0;36mtrain_nn_model\u001b[0;34m(X, y, cv, input_dimension, learning_rate)\u001b[0m\n\u001b[1;32m     14\u001b[0m         model\u001b[38;5;241m.\u001b[39madd(Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     15\u001b[0m         model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMeanSquaredError\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m              optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[1;32m     17\u001b[0m              metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR2Score\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 18\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m         score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#         print('Total loss on testing data:', score[0])\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#         print('Accuracy of testing data:', score[1])\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/vg/6hqbf5pj4cn8_n2xsv3x2f940000gn/T/__autograph_generated_file760_71j4.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/hiradh/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/hiradh/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/hiradh/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/hiradh/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/hiradh/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/hiradh/miniconda3/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_95\" is incompatible with the layer: expected shape=(None, 225), found shape=(None, 50)\n"
     ]
    }
   ],
   "source": [
    "atf_df = load_data('Atf4.txt', header=1)\n",
    "atf_X, atf_y, atf_cv = preprocess_data(atf_df, '1mer', normalize=False)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    print(f\"Average Neural Net r-squared for Atf4 1-mer: {train_nn_model(atf_X, atf_y, atf_cv, 225, 0.01)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d630a7b7-9747-4449-9c24-aa80dec0d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f134e824-1731-4749-95ef-37c6457b4f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Linear Regression r-squared for Atf4 1-mer: -0.00013149165587644784\n"
     ]
    }
   ],
   "source": [
    "def train_linreg_model(X, y, cv):\n",
    "    # results\n",
    "    mse_scores = []; r_squared_scores = []\n",
    "    \n",
    "    # Initialize Linear Regression model\n",
    "    #model = LinearRegression()\n",
    "    #model = Lasso(alpha=0.001)\n",
    "    #model = Ridge(alpha=0.001)\n",
    "    model = ElasticNet(alpha=0.001, l1_ratio=0.5)\n",
    "    \n",
    "    # Loop over each fold\n",
    "    for train_index, valid_index in cv.split(X):\n",
    "        # Split data\n",
    "        X_train, X_valid = X[train_index], X[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "    \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on valid set\n",
    "        predictions = model.predict(X_valid)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        mse = mean_squared_error(y_valid, predictions)\n",
    "        mse_scores.append(mse)\n",
    "        \n",
    "        r_squared = model.score(X_valid, y_valid)\n",
    "        r_squared_scores.append(r_squared)\n",
    "        \n",
    "    average_mse = np.mean(mse_scores)\n",
    "    average_r_squared = np.mean(r_squared_scores)\n",
    "    return average_r_squared\n",
    "\n",
    "print(\"Average Linear Regression r-squared for Atf4 1-mer: \" + str(train_linreg_model(atf_X, atf_y, atf_cv)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
